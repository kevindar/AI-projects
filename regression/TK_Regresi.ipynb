{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chart_studio.plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ab22056d9a88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mchart_studio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_notebook_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chart_studio.plotly'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chart_studio.plotly as py\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawMissing(df):\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    return missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = mx + b\n",
    "class gradient:\n",
    "    def __init__(self, m, b):\n",
    "        self.m = m\n",
    "        self.b = b\n",
    "    def value(self, x):\n",
    "        return self.m * x + self.b\n",
    "    \n",
    "def cost_function(x, y, gradient):\n",
    "    sum = 0\n",
    "    total_sample = x.shape[0]\n",
    "    for i in range(total_sample):\n",
    "        real = y[i]\n",
    "        hypothesis = gradient.value(x[i])\n",
    "        sum += (hypothesis - real)**2\n",
    "    return np.sum(sum / (2 * total_sample))\n",
    "\n",
    "def JmDerivative(x, y, gradient):\n",
    "    sum = 0\n",
    "    total_sample = x.shape[0]\n",
    "    for i in range(total_sample):\n",
    "        real = y[i]\n",
    "        hypothesis = gradient.value(x[i])\n",
    "        sum += (hypothesis - real) * x[i]\n",
    "    return np.sum(sum / total_sample)\n",
    "\n",
    "def JbDerivative(x, y, gradient):\n",
    "    sum = 0\n",
    "    total_sample = x.shape[0]\n",
    "    for i in range(total_sample):\n",
    "        real = y[i]\n",
    "        hypothesis = gradient.value(x[i])\n",
    "        sum += hypothesis - real\n",
    "    return np.sum(sum / total_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearRegression(x, y, m=0, mStep=0.1, mTry=1000, b=0, bStep=0.1, bTry=1000): \n",
    "    costBest = sys.maxsize\n",
    "    gradientBest = None\n",
    "    for i in range(mTry):\n",
    "        for j in range(bTry):\n",
    "            mTest = m + mStep * i\n",
    "            bTest = b + bStep * j\n",
    "            result = cost_function(x, y, gradient(mTest, bTest))\n",
    "            if (result < costBest):\n",
    "                costBest = result\n",
    "                gradientBest = gradient(mTest, bTest)\n",
    "                # 0 is the best cost we can get, so return anyway\n",
    "                if (result == 0): return gradientBest\n",
    "    return gradientBest\n",
    "\n",
    "def BatchGD(x, y, m, b, learningRate, iter):\n",
    "    mList = []\n",
    "    bList = []\n",
    "    cList = []\n",
    "    for i in range(iter):\n",
    "        derivative_cost_m = JmDerivative(x, y, gradient(m, b))\n",
    "        derivative_cost_b = JbDerivative(x, y, gradient(m, b))\n",
    "        m = m - learningRate * derivative_cost_m\n",
    "        b = b - learningRate * derivative_cost_b\n",
    "        c = cost_function(x, y, gradient(m, b))\n",
    "        mList.append(m)\n",
    "        bList.append(b)\n",
    "        cList.append(c)\n",
    "    return mList, bList, cList\n",
    "\n",
    "def StochasticGD(x, y, m, b, learningRate):\n",
    "    \n",
    "    def CostDerivative(x1, y1, m, b, biasDerivative=False):\n",
    "        hypothesis = gradient(m, b).value(x1)\n",
    "        if (biasDerivative):\n",
    "            return np.sum(hypothesis - y1)\n",
    "        return np.sum((hypothesis - y1) * x1)\n",
    "    \n",
    "    mList = []\n",
    "    bList = []\n",
    "    cList = []\n",
    "    total_sample = x.shape[0]\n",
    "    for i in range(total_sample):\n",
    "        derivative_m = CostDerivative(x[i], y[i], m, b, False)\n",
    "        derivative_b = CostDerivative(x[i], y[i], m, b, True)\n",
    "        m = m - learningRate * derivative_m\n",
    "        b = b - learningRate * derivative_b\n",
    "        c = cost_function(x, y, gradient(m, b))\n",
    "        mList.append(m)\n",
    "        bList.append(b)\n",
    "        cList.append(c)\n",
    "    return mList, bList, cList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacsv  = pd.read_csv('input/house/train.csv')\n",
    "dataset  = pd.DataFrame(datacsv, columns = ['OverallCond'])\n",
    "targets  = pd.DataFrame(datacsv, columns = ['SalePrice'])\n",
    "\n",
    "missing_dataset = DrawMissing(dataset)\n",
    "display(missing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.head())\n",
    "print(targets.head())\n",
    "\n",
    "targets = targets.to_numpy()\n",
    "dataset = dataset.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresi Metode Statistika "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paramaters for Guessing Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mStart = 10\n",
    "mStep  = 0.5\n",
    "mIter  = 100\n",
    "bStart = 50000\n",
    "bStep  = 10000\n",
    "bIter  = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = LinearRegression(dataset, targets, mStart, mStep, mIter, bStart, bStep, bIter)\n",
    "\n",
    "minIndex = np.argmin(dataset)\n",
    "maxIndex = np.argmax(dataset)\n",
    "\n",
    "xGrad = [dataset[minIndex], dataset[maxIndex]]\n",
    "yGrad = [best.value(dataset[minIndex]), best.value(dataset[maxIndex])]\n",
    "\n",
    "print(\"Cost: \", cost_function(dataset, targets, best))\n",
    "print(\"m: \", best.m)\n",
    "print(\"b: \", best.b)\n",
    "\n",
    "plt.scatter(dataset, targets, label='Data')\n",
    "plt.plot(xGrad, yGrad, color='Red', label='y = mx + b')\n",
    "plt.xlabel(\"X (Input)\")\n",
    "plt.ylabel(\"Y (Output)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for Using Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningRate = 0.01\n",
    "iteration = 100\n",
    "mStart = 10\n",
    "bStart = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresi Metode Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b, cost = BatchGD(dataset, targets, mStart, bStart, learningRate, iteration)\n",
    "\n",
    "minIndex = np.argmin(cost)\n",
    "print(\"Minimum Cost: \", cost[minIndex])\n",
    "print(\"m: \", m[minIndex])\n",
    "print(\"b: \", b[minIndex])\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(m, b, cost, 'Red')\n",
    "ax.set_xlabel('Weight (m)')\n",
    "ax.set_ylabel('Bias (b)')\n",
    "ax.set_zlabel('Cost (J)')\n",
    "ax.set_title('Batch Gradient Descent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresi Stokastik Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, b, cost = StochasticGD(dataset, targets, mStart, bStart, learningRate)\n",
    "\n",
    "minIndex = np.argmin(cost)\n",
    "print(\"Minimum Cost: \", cost[minIndex])\n",
    "print(\"m: \", m[minIndex])\n",
    "print(\"b: \", b[minIndex])\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot3D(m, b, cost, 'Red')\n",
    "ax.set_xlabel('Weight (m)')\n",
    "ax.set_ylabel('Bias (b)')\n",
    "ax.set_zlabel('Cost (J)')\n",
    "ax.set_title('Batch Gradient Descent')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
